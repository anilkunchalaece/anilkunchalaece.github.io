<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.2.2">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2024-05-18T12:30:40+01:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Anil Kunchala</title><subtitle>a &lt;i&gt; Tinkerers &lt;/i&gt; log about his experiments with few things he came across</subtitle><author><name>Anil Kunchala</name></author><entry><title type="html">Towards A Framework for Privacy-Preserving Pedestrian Analysis</title><link href="http://localhost:4000/phd/publication/projects/2024/02/19/privacy-framework-paper.html" rel="alternate" type="text/html" title="Towards A Framework for Privacy-Preserving Pedestrian Analysis" /><published>2024-02-19T00:00:00+00:00</published><updated>2024-02-19T00:00:00+00:00</updated><id>http://localhost:4000/phd/publication/projects/2024/02/19/privacy-framework-paper</id><content type="html" xml:base="http://localhost:4000/phd/publication/projects/2024/02/19/privacy-framework-paper.html"><![CDATA[<h2 id="overview">Overview</h2>
<p><strong>Title:</strong> Towards A Framework for Privacy-Preserving Pedestrian Analysis</p>

<p><strong>Published in:</strong> 2023 IEEE CVF Winter Conference on Applications of Computer Vision (WACV 2023)</p>

<p><img src="http://localhost:4000/assets/images/wacv2023/wacv2023-results.png" alt="image" />
<strong>Qualitative results for the proposed and baseline methods</strong></p>

<h2 id="abstract">Abstract</h2>
<p>The design of pedestrian-friendly infrastructures plays a crucial role in creating sustainable transportation in urban environments. Analyzing pedestrian behaviour in response to existing infrastructure is pivotal to planning, maintaining, and creating more pedestrian-friendly facilities. Many approaches have been proposed to extract such behaviour by applying deep learning models to video data. Video data, however, includes an broad spectrum of privacy-sensitive information about individuals, such as their location at a given time or who they are with. Most of the existing mod-
els use privacy-invasive methodologies to track, detect, and analyse individual or group pedestrian behaviour patterns.</p>

<p>As a step towards privacy-preserving pedestrian analysis, this paper introduces a framework to anonymize all pedestrians before analyzing their behaviors. The proposed framework leverages recent developments in 3D wireframe reconstruction and digital in-painting to represent pedestrians with quantitative wireframes by removing their images while preserving pose, shape, and background scene context. To evaluate the proposed framework, a generic metric is introduced for each of privacy and utility. Experimental evaluation on widely-used datasets shows that the proposed framework outperforms traditional and state-of-the-art image filtering approaches by generating best privacy utility
trade-off.</p>

<h2 id="key-contributions">Key Contributions</h2>
<ul>
  <li>A novel end-to-end framework is introduced to generate a privacy-enhanced version of a given video or
image sequence.</li>
  <li>Both a generic utility and statistical similarity-based privacy metrics are proposed to evaluate the privacy utility trade-off.</li>
</ul>

<h2 id="overview-of-the-proposed-framework">Overview of the proposed framework</h2>
<p><img src="http://localhost:4000/assets/images/wacv2023/wacv2023-framework.png" alt="image" /></p>

<h2 id="privacy-utility-trade-off">Privacy-Utility Trade-off</h2>
<p><img src="http://localhost:4000/assets/images/wacv2023/wacv2023-results-plots.png" alt="image" /></p>

<h2 id="publication-link-and-code">Publication Link and Code</h2>
<ul>
  <li><a href="https://arrow.tudublin.ie/cgi/viewcontent.cgi?article=1411&amp;context=scschcomcon" target="_blank">Read the full paper</a></li>
  <li><a href="https://www.youtube.com/watch?v=Ke5vPS9fwUA" target="_blank">WACV 2023 Presentation Video</a></li>
  <li><a href="https://drive.google.com/file/d/1ZROKNr6W2BqqKL1qUM2tOAF-ckC4zrZi/view?usp=sharing" target="_blank">WACV 2023 Presentation Slides</a></li>
  <li><a href="https://drive.google.com/file/d/1DIcMZizTPD4LhC8Ir7pYvc7vNcjhyS4v/view?usp=sharing" target="_blank">WACV 2023 Poster</a></li>
  <li><a href="https://github.com/anilkunchalaece/privacyFramework" target="_blank">Source Code</a></li>
</ul>]]></content><author><name>Anil Kunchala</name></author><category term="[&quot;Projects&quot;]" /><summary type="html"><![CDATA[Towards A Framework for Privacy-Preserving Pedestrian Analysis]]></summary></entry><entry><title type="html">Bray To Graystones- Ireland</title><link href="http://localhost:4000/hiking/travel/2024/02/18/bray.html" rel="alternate" type="text/html" title="Bray To Graystones- Ireland" /><published>2024-02-18T00:00:00+00:00</published><updated>2024-02-18T00:00:00+00:00</updated><id>http://localhost:4000/hiking/travel/2024/02/18/bray</id><content type="html" xml:base="http://localhost:4000/hiking/travel/2024/02/18/bray.html"><![CDATA[<p>Route</p>

<p><img src="http://localhost:4000/assets/maps/bray-greystones-cliff-walk.png" alt="image" /></p>

<p>Few Snaps
<img src="http://localhost:4000/assets/images/bray/20240218_120542.jpg" alt="image" />
<img src="http://localhost:4000/assets/images/bray/20240218_122356.jpg" alt="image" />
<img src="http://localhost:4000/assets/images/bray/20240218_120711.jpg" alt="image" /></p>]]></content><author><name>Anil Kunchala</name></author><category term="[&quot;Travel&quot;]" /><summary type="html"><![CDATA[A Trip to Bray]]></summary></entry><entry><title type="html">SMPL-based 3D Pedestrian Pose Prediction</title><link href="http://localhost:4000/phd/publication/projects/2024/02/15/smpl-paper.html" rel="alternate" type="text/html" title="SMPL-based 3D Pedestrian Pose Prediction" /><published>2024-02-15T00:00:00+00:00</published><updated>2024-02-15T00:00:00+00:00</updated><id>http://localhost:4000/phd/publication/projects/2024/02/15/smpl-paper</id><content type="html" xml:base="http://localhost:4000/phd/publication/projects/2024/02/15/smpl-paper.html"><![CDATA[<h2 id="overview">Overview</h2>
<p><strong>Title:</strong> SMPL-Based 3D Pedestrian Pose Prediction</p>

<p><strong>Published in:</strong> 2021 16th IEEE International Conference on Automatic Face and Gesture Recognition (FG 2021)</p>

<p><img src="http://localhost:4000/assets/images/fg2021/ADV_SMPL_AWARE.png" alt="image" />
<strong>Adversarial SMPL-based Recurrent Neural Network Architecture</strong></p>

<h2 id="abstract">Abstract</h2>
<p>In 3D pedestrian pose prediction, joint-rotation-based pose representation is extensively used due to the unconstrained degree of freedom for each joint and its ability to regress the 3D statistical wireframe. However, all the existing joint-rotation-based pose prediction approaches ignore the centrality of the distinct pose parameter components and are consequently prone to suffer from error accumulation along the kinematic chain, which results in unnatural human poses. In joint-rotationbased pose prediction, Skinned Multi-Person Linear (SMPL) parameters are widely used to represent pedestrian pose.</p>

<p>In this work, a novel SMPL-based pose prediction network is proposed to address the centrality of each SMPL component by distributing the network weights among them. Furthermore, to constrain the network to generate only plausible human poses, an adversarial training approach is employed. The effectiveness of the proposed network is evaluated using the PedX and BEHAVE datasets. The proposed approach significantly outperforms state-of-the-art methods with improved prediction accuracy and generates plausible human pose predictions.</p>

<h2 id="key-contributions">Key Contributions</h2>
<ul>
  <li>We designed a multi-layer perception generative adversarial network to penalize the network for unnatural poses while allowing natural one.</li>
  <li>The SMPL-based architecture is proposed to address the centrality of global rotation and translation parameters with respect to the pose parameters</li>
</ul>

<h2 id="qualitative-results">Qualitative Results</h2>
<p><img src="http://localhost:4000/assets/images/fg2021/ADV_SMPL_AWARE_Results.png" alt="image" /></p>

<h2 id="publication-link-and-code">Publication Link and Code</h2>
<ul>
  <li><a href="https://arrow.tudublin.ie/cgi/viewcontent.cgi?article=1374&amp;context=scschcomcon" target="_blank">Read the full paper</a></li>
  <li><a href="https://youtu.be/OeOTEcbYsrI" target="_blank">FG 2021 Presentation Video</a></li>
  <li><a href="https://drive.google.com/file/d/1yl6l8_vDKse4vCQ_LtTk6dgMY3LTmAqw/view?usp=sharing" target="_blank">FG 2021 Presentation Slides</a></li>
  <li><a href="https://drive.google.com/file/d/1K3FvySkvguGt_yD-mFijZyALVjKBzN14/view?usp=sharing" target="_blank">FG 2021 Poster</a></li>
  <li><a href="https://github.com/anilkunchalaece/ADV-SA-LSTM" target="_blank">Source Code</a></li>
</ul>]]></content><author><name>Anil Kunchala</name></author><category term="[&quot;Projects&quot;]" /><summary type="html"><![CDATA[Adversarial SMPL based 3D Pedestrian Pose Prediction]]></summary></entry><entry><title type="html">Mourne Mountains - Northern Ireland</title><link href="http://localhost:4000/hiking/travel/2022/05/28/Mourne-Mountains.html" rel="alternate" type="text/html" title="Mourne Mountains - Northern Ireland" /><published>2022-05-28T00:00:00+01:00</published><updated>2022-05-28T00:00:00+01:00</updated><id>http://localhost:4000/hiking/travel/2022/05/28/Mourne-Mountains</id><content type="html" xml:base="http://localhost:4000/hiking/travel/2022/05/28/Mourne-Mountains.html"><![CDATA[<p>Route</p>

<p><img src="http://localhost:4000/assets/maps/21-may-hillwalkerclub-mourne-mountains.png" alt="image" /></p>

<p>Few Snaps
<img src="http://localhost:4000/assets/images/mourne/IMG_20220521_110320.jpg" alt="image" />
<img src="http://localhost:4000/assets/images/mourne/IMG_20220521_131018.jpg" alt="image" />
<img src="http://localhost:4000/assets/images/mourne/IMG_20220521_140154.jpg" alt="image" />
<img src="http://localhost:4000/assets/images/mourne/IMG_20220521_160438.jpg" alt="image" /></p>]]></content><author><name>Anil Kunchala</name></author><category term="[&quot;Travel&quot;]" /><summary type="html"><![CDATA[A Trip to Mourne Mountains]]></summary></entry><entry><title type="html">Wicklow Mountains, Tonelagee - Ireland</title><link href="http://localhost:4000/hiking/travel/2022/04/24/Tonelagee.html" rel="alternate" type="text/html" title="Wicklow Mountains, Tonelagee - Ireland" /><published>2022-04-24T00:00:00+01:00</published><updated>2022-04-24T00:00:00+01:00</updated><id>http://localhost:4000/hiking/travel/2022/04/24/Tonelagee</id><content type="html" xml:base="http://localhost:4000/hiking/travel/2022/04/24/Tonelagee.html"><![CDATA[<p>Route</p>

<p><img src="http://localhost:4000/assets/maps/glendalough-upper-lake-tonelagee.png" alt="image" /></p>

<p>Few Snaps
<img src="http://localhost:4000/assets/images/tonelagee/IMG_20220424_140145.jpg" alt="image" />
<img src="http://localhost:4000/assets/images/tonelagee/IMG_20220424_140258.jpg" alt="image" /></p>]]></content><author><name>Anil Kunchala</name></author><category term="[&quot;Travel&quot;]" /><summary type="html"><![CDATA[A Trip to Wicklow Mountains]]></summary></entry><entry><title type="html">Mount Leinster- Ireland</title><link href="http://localhost:4000/hiking/travel/2022/04/16/mountLeinster.html" rel="alternate" type="text/html" title="Mount Leinster- Ireland" /><published>2022-04-16T00:00:00+01:00</published><updated>2022-04-16T00:00:00+01:00</updated><id>http://localhost:4000/hiking/travel/2022/04/16/mountLeinster</id><content type="html" xml:base="http://localhost:4000/hiking/travel/2022/04/16/mountLeinster.html"><![CDATA[<p>Route</p>

<p><img src="http://localhost:4000/assets/maps/mount-leinster.png" alt="image" /></p>

<p>Few Snaps
<img src="http://localhost:4000/assets/images/leinster/IMG_20220416_133145.jpg" alt="image" />
<img src="http://localhost:4000/assets/images/leinster/IMG_20220416_133331.jpg" alt="image" /></p>]]></content><author><name>Anil Kunchala</name></author><category term="[&quot;Travel&quot;]" /><summary type="html"><![CDATA[A Trip to Mount Leinster]]></summary></entry><entry><title type="html">Xnect - Installation and running demo</title><link href="http://localhost:4000/machine%20learning/2020/10/28/XNect-setup.html" rel="alternate" type="text/html" title="Xnect - Installation and running demo" /><published>2020-10-28T00:00:00+00:00</published><updated>2020-10-28T00:00:00+00:00</updated><id>http://localhost:4000/machine%20learning/2020/10/28/XNect-setup</id><content type="html" xml:base="http://localhost:4000/machine%20learning/2020/10/28/XNect-setup.html"><![CDATA[<p>In this Post I will show how to install <a href="https://gvv.mpi-inf.mpg.de/projects/XNect/">XNect</a> and Run the demo in C/C++ Library provided by xNect Team.</p>

<p>In summary you need to install following dependencies</p>
<ol>
  <li>OpenCV 3.4.11 - <em>recommended , dont use Opencv 4</em></li>
  <li>Protobuf</li>
  <li>Boost 1.58.0</li>
  <li>CUDA - <em>8 or 9 recommened but I tested with 10</em></li>
  <li>Caffe - <em>need to make few modifications before installation</em></li>
</ol>

<h4 id="machine-configuration">Machine Configuration</h4>
<p>I tested using machine with following configuration</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>DISTRIB_ID=Ubuntu
DISTRIB_RELEASE=19.10
DISTRIB_CODENAME=eoan
x86_64
Kernal - 5.3.0-64-generic 
</code></pre></div></div>

<p><img src="http://localhost:4000/assets/images/nvidia_info.jpg" alt="image" /></p>

<h4 id="1-installing-opencv-and-contrib-libs">1. installing openCV and contrib libs</h4>
<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  wget <span class="nt">-c</span>  <span class="nt">-O</span> opencv-3.4.11.tar.gz https://github.com/opencv/opencv/archive/3.4.11.tar.gz       
  <span class="nb">tar </span>xvzf opencv-3.4.11.tar.gz

  wget <span class="nt">-c</span> <span class="nt">-O</span> opencv_contrib-3.4.11 https://github.com/opencv/opencv_contrib/archive/3.4.11.tar.gz  
  <span class="nb">tar </span>xvzf opencv_contrib-3.4.11.tar.gz  

  <span class="nb">rm </span>opencv-3.4.11.tar.gz opencv_contrib-3.4.11.tar.gz

  <span class="nb">cd </span>opencv-3.4.11
  <span class="nb">mkdir </span>build
  <span class="nb">cd </span>build

  <span class="c"># Run cmake - Check XNect readme.md for flags</span>
  cmake <span class="nt">-D</span> <span class="nv">CMAKE_BUILD_TYPE</span><span class="o">=</span>RELEASE <span class="nt">-D</span> <span class="nv">CMAKE_INSTALL_PREFIX</span><span class="o">=</span>/usr/local <span class="nt">-D</span> <span class="nv">INSTALL_C_EXAMPLES</span><span class="o">=</span>ON <span class="nt">-D</span> <span class="nv">INSTALL_PYTHON_EXAMPLES</span><span class="o">=</span>ON <span class="nt">-D</span> <span class="nv">OPENCV_EXTRA_MODULES_PATH</span><span class="o">=</span>/home/anil/Documents/xNect/opencv_contrib-3.4.11/modules <span class="nt">-D</span> <span class="nv">BUILD_EXAMPLES</span><span class="o">=</span>ON <span class="nt">-D</span> <span class="nv">WITH_TBB</span><span class="o">=</span>ON <span class="nt">-D</span> <span class="nv">BUILD_NEW_PYTHON_SUPPORT</span><span class="o">=</span>ON <span class="nt">-D</span> <span class="nv">WITH_V4L</span><span class="o">=</span>ON <span class="nt">-D</span> <span class="nv">WITH_QT</span><span class="o">=</span>ON <span class="nt">-D</span> <span class="nv">WITH_OPENGL</span><span class="o">=</span>ON <span class="nt">-D</span> <span class="nv">BUILD_TIFF</span><span class="o">=</span>ON ..

  make <span class="nt">-j</span><span class="si">$(</span><span class="nb">nproc</span><span class="si">)</span>
  <span class="nb">sudo </span>make <span class="nb">install
  sudo </span>ldconfig
</code></pre></div></div>

<p>Once installtion completed, check it</p>
<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>python
<span class="o">&gt;&gt;&gt;</span> import cv2
<span class="o">&gt;&gt;&gt;</span> cv2.__version__
<span class="s1">'3.4.11'</span>
</code></pre></div></div>

<h4 id="2-installing-protobuf">2. installing protobuf</h4>
<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">sudo </span>apt-get <span class="nb">install </span>autoconf automake libtool curl make g++ unzip <span class="nt">-y</span>
git clone https://github.com/google/protobuf.git
<span class="nb">cd </span>protobuf
git submodule update <span class="nt">--init</span> <span class="nt">--recursive</span>
./autogen.sh
./configure <span class="nv">CFLAGS</span><span class="o">=</span><span class="s2">"-fPIC"</span> <span class="nv">CXXFLAGS</span><span class="o">=</span><span class="s2">"-fPIC"</span>  <span class="o">(</span>Why ? I dont know - Check XNect Readme<span class="o">)</span>
<span class="nb">sudo </span>make <span class="nb">install
sudo </span>ldconfig
</code></pre></div></div>

<h4 id="3-installing-boost-1580">3. installing boost 1.58.0</h4>
<p>download  boost from <a href="https://www.boost.org/users/history/">here</a></p>
<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">tar </span>xvzf boost-1.58.tar
<span class="nb">cd </span>boost-1.58/tools/build
/bootstrap.sh <span class="nt">--prefix</span><span class="o">=</span>path/to/installation/prefix
./b2 <span class="nb">install</span>
</code></pre></div></div>
<ul>
  <li>Add PREFIX/bin to your PATH environment variable.</li>
</ul>

<h4 id="4-installing-caffe">4. installing caffe</h4>
<p>BVLC GitHub repository and grab the latest version of Caffe</p>
<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>git clone https://github.com/BVLC/caffe.git
<span class="nb">cd </span>caffe
<span class="c">#copy make file </span>
<span class="nb">cp </span>Makefile.config.example Makefile.config
</code></pre></div></div>

<p>and make the following edits to <em>Makefile.config</em> - these are used to specify that we need to install caffe with GPU and CUDA support</p>

<div class="language-config highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># cuDNN acceleration switch (uncomment to build with cuDNN).
</span><span class="n">USE_CUDNN</span> := <span class="m">1</span>

<span class="c"># Uncomment if you're using OpenCV 3
</span><span class="n">OPENCV_VERSION</span> := <span class="m">3</span>

<span class="c"># We need to be able to find Python.h and numpy/arrayobject.h.
</span><span class="n">PYTHON_INCLUDE</span> := /<span class="n">usr</span>/<span class="n">include</span>/<span class="n">python2</span>.<span class="m">7</span> \
        /<span class="n">usr</span>/<span class="n">local</span>/<span class="n">lib</span>/<span class="n">python2</span>.<span class="m">7</span>/<span class="n">dist</span>-<span class="n">packages</span>/<span class="n">numpy</span>/<span class="n">core</span>/<span class="n">include</span>

<span class="c"># Uncomment to support layers written in Python (will link against    Python libs)
</span><span class="n">WITH_PYTHON_LAYER</span> := <span class="m">1</span>

<span class="c"># Whatever else you find you need goes here.
</span><span class="n">INCLUDE_DIRS</span> := $(<span class="n">PYTHON_INCLUDE</span>) /<span class="n">usr</span>/<span class="n">local</span>/<span class="n">include</span> /<span class="n">usr</span>/<span class="n">include</span>/<span class="n">hdf5</span>/<span class="n">serial</span>
<span class="n">LIBRARY_DIRS</span> := $(<span class="n">PYTHON_LIB</span>) /<span class="n">usr</span>/<span class="n">local</span>/<span class="n">lib</span> /<span class="n">usr</span>/<span class="n">lib</span> /<span class="n">usr</span>/<span class="n">lib</span>/<span class="n">x86_64</span>-<span class="n">linux</span>-<span class="n">gnu</span>/<span class="n">hdf5</span>/<span class="n">serial</span>/
</code></pre></div></div>

<p>and based on the cuda version you are using uncomment architectures</p>

<div class="language-config highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># CUDA architecture setting: going with all of them.
# For CUDA &lt; 6.0, comment the *_50 through *_61 lines for compatibility.
# For CUDA &lt; 8.0, comment the *_60 and *_61 lines for compatibility.
# For CUDA &gt;= 9.0, comment the *_20 and *_21 lines for compatibility.
</span><span class="n">CUDA_ARCH</span> := 
		<span class="c"># -gencode arch=compute_20,code=sm_20 \
</span>		<span class="c"># -gencode arch=compute_20,code=sm_21 \
</span>		-<span class="n">gencode</span> <span class="n">arch</span>=<span class="n">compute_30</span>,<span class="n">code</span>=<span class="n">sm_30</span> \
		-<span class="n">gencode</span> <span class="n">arch</span>=<span class="n">compute_35</span>,<span class="n">code</span>=<span class="n">sm_35</span> \
		-<span class="n">gencode</span> <span class="n">arch</span>=<span class="n">compute_50</span>,<span class="n">code</span>=<span class="n">sm_50</span> \
		-<span class="n">gencode</span> <span class="n">arch</span>=<span class="n">compute_52</span>,<span class="n">code</span>=<span class="n">sm_52</span> \
		-<span class="n">gencode</span> <span class="n">arch</span>=<span class="n">compute_60</span>,<span class="n">code</span>=<span class="n">sm_60</span> \
		-<span class="n">gencode</span> <span class="n">arch</span>=<span class="n">compute_61</span>,<span class="n">code</span>=<span class="n">sm_61</span> \
		-<span class="n">gencode</span> <span class="n">arch</span>=<span class="n">compute_61</span>,<span class="n">code</span>=<span class="n">compute_61</span>
</code></pre></div></div>
<h5 id="41-removing-clip-layer-and-adding-other-necessary-files">4.1 Removing clip layer and adding other necessary files</h5>
<p>I’m just copy + pasting steps/info in XNect readme.md document. Please refer document for more info (I’m not sure whether I can add that Info here are not due to licencing issues)</p>
<ol>
  <li>Copy folders from XNect source to caffe (Include and src)</li>
  <li>Make necessary changes to <em>caffe.proto</em> ( Need to add extra layers )</li>
  <li>Add new layer description</li>
  <li>Remove cliplayer from caffe - incluing .hpp , .cpp files</li>
</ol>

<h5 id="42-compile-caffe">4.2 compile caffe</h5>
<p>API comes with gcc-6.4 support , I’m unable to compile this with current gcc in my system i.e gcc-9, so In order to specify different compiler for gcc<br />
<a href="https://stackoverflow.com/questions/17275348/how-to-specify-new-gcc-path-for-cmake">ref</a></p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">export </span><span class="nv">CC</span><span class="o">=</span>/usr/local/bin/gcc-6.4
<span class="nb">export </span><span class="nv">CXX</span><span class="o">=</span>/usr/local/bin/g++-6.4
<span class="c">#cmake /path/to/your/project</span>
<span class="c">#make</span>
</code></pre></div></div>
<p>Run cmake and make for caffe</p>
<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>cmake <span class="nt">-DProtobuf_LIBRARY_DEBUG</span><span class="o">=</span>/home/anil/Documents/xNect/protobuf/src/.libs/libprotobuf.so <span class="nt">-DProtobuf_PROTOC_EXECUTABLE</span><span class="o">=</span>/home/anil/Documents/xNect/protobuf/src/.libs/protoc <span class="nt">-DProtobuf_LIBRARY_RELEASE</span><span class="o">=</span>/home/anil/Documents/xNect/protobuf/src/.libs/libprotobuf.a  <span class="nt">-DProtobuf_LITE_LIBRARY_RELEASE</span><span class="o">=</span>/home/anil/Documents/xNect/protobuf/src/.libs/libprotobuf-lite.a <span class="nt">-DBOOST_INCLUDEDIR</span><span class="o">=</span>/usr/include/boost/  <span class="nt">-DBOOST_LIBRARYDIR</span><span class="o">=</span>/home/anil/Documents/xNect/boost/lib <span class="nt">-DProtobuf_INCLUDE_DIR</span><span class="o">=</span>/home/anil/Documents/xNect/protobuf/src/ <span class="nt">-DProtobuf_PROTOC_LIBRARY_RELEASE</span><span class="o">=</span>/home/anil/Documents/xNect/protobuf/src/.libs/libprotoc.so ..

make all <span class="nt">-j</span><span class="si">$(</span><span class="nb">nproc</span><span class="si">)</span> <span class="o">&amp;&amp;</span> make <span class="nb">test</span> <span class="nt">-j</span><span class="si">$(</span><span class="nb">nproc</span><span class="si">)</span> <span class="o">&amp;&amp;</span> make runtest <span class="nt">-j</span><span class="si">$(</span><span class="nb">nproc</span><span class="si">)</span> <span class="o">&amp;&amp;</span> make pycaffe <span class="nt">-j</span><span class="si">$(</span><span class="nb">nproc</span><span class="si">)</span>
</code></pre></div></div>

<p>Once done, Add follwing to .bashrc</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>export PYTHONPATH=/home/anil/Documents/xNect/caffe/python:$PYTHONPATH
</code></pre></div></div>

<p>check caffe</p>
<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>python
<span class="o">&gt;&gt;&gt;</span> import caffe
</code></pre></div></div>

<h5 id="build-project-and-run-demo">build project and run demo</h5>
<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>cmake <span class="nt">-DOpenCV_DIR</span><span class="o">=</span>/usr/share/opencv  <span class="nt">-DCaffe_DIR</span><span class="o">=</span>/home/anil/Documents/xNect/caffe/build ..
make <span class="nt">-j</span><span class="si">$(</span><span class="nb">nproc</span><span class="si">)</span>
<span class="nb">cd</span> ../bin/Release
./XNECT
</code></pre></div></div>

<h5 id="references">References</h5>
<ol>
  <li>I found a nice article about <a href="https://chunml.github.io/ChunML.github.io/project/Installing-Caffe-Ubuntu/">installing caffe in ubuntu</a>.</li>
  <li><a href="https://gist.github.com/diegopacheco/cd795d36e6ebcd2537cd18174865887b">Protobuf installation</a></li>
  <li><a href="https://www.boost.org/doc/libs/1_66_0/more/getting_started/unix-variants.html">Boost 1.58 Installation</a></li>
</ol>]]></content><author><name>Anil Kunchala</name></author><category term="Machine Learning" /><category term="Machine Learning" /><summary type="html"><![CDATA[In this post I will explain how to setup XNect and run the demo provided in the example]]></summary></entry><entry><title type="html">Simple Project</title><link href="http://localhost:4000/machine%20learning/projects/2020/10/26/projectOne.html" rel="alternate" type="text/html" title="Simple Project" /><published>2020-10-26T00:00:00+00:00</published><updated>2020-10-26T00:00:00+00:00</updated><id>http://localhost:4000/machine%20learning/projects/2020/10/26/projectOne</id><content type="html" xml:base="http://localhost:4000/machine%20learning/projects/2020/10/26/projectOne.html"><![CDATA[<!-- You just need to add 

~~~yaml
category: 
  - Projects
~~~ -->

<p>This section is just my notepad. I post stuff of which I might do in future</p>

<h1 id="todo"><strong>TODO</strong></h1>

<h2 id="learning-stuff"><em>Learning Stuff</em></h2>
<ol>
  <li>Basic DL model using <a href="https://www.cs.toronto.edu/~kriz/cifar.html">CIFAR</a> and Pytorch
    <ol>
      <li>Download CIFAR using <code class="language-plaintext highlighter-rouge">wget https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz</code></li>
    </ol>
  </li>
  <li>Re-implement it using Pytorch Lightning</li>
  <li>Hyper optimization tuning using RayTune
    <ol>
      <li>Training parameters (like learning rate) tuning</li>
      <li>Model parameters (No Of parameters in each layer &amp; No of Layers) tuning</li>
    </ol>
  </li>
  <li>Model Interpretability using <a href="https://captum.ai/">Captum</a>
    <ol>
      <li>Explore model input interpretability for images</li>
    </ol>
  </li>
</ol>

<h2 id="openmmlab"><em>OpenMMLab</em></h2>
<ol>
  <li>Test MMDetection</li>
  <li>Test MMPose</li>
  <li>Try to combine both detection and pose</li>
</ol>

<h3 id="mmdetection-logs">MMDetection Logs</h3>
<ul>
  <li>Got Error - <em>KeyError: ‘Cascade Mask R-CNN’</em>
    <ul>
      <li>Refer <a href="https://github.com/open-mmlab/mmdetection/issues/8122">Issue</a> and [Ans] (https://github.com/open-mmlab/mmdetection/issues/8122#issuecomment-1158658158)</li>
    </ul>
  </li>
</ul>]]></content><author><name>Anil Kunchala</name></author><category term="[&quot;Projects&quot;]" /><summary type="html"><![CDATA[How to add Project in bog]]></summary></entry></feed>